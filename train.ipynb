{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#由于地图中左转较多，为防止小车易朝左偏出车道，对部分训练图片进行水平翻转，角度取负值。\n",
    "def horizontal_flip(img, degree):\n",
    "    choice = np.random.choice([0, 1])\n",
    "    if choice == 1:\n",
    "        img, degree = cv2.flip(img, 1), -degree\n",
    "    return (img, degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#进行色彩空间转换并随机调整亮度。\n",
    "def random_brightness(img, degree):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    alpha = np.random.uniform(low = 0.1, high = 1.0, size = None)\n",
    "    v = hsv[:, :, 2]\n",
    "    v = v * alpha\n",
    "    hsv[:, :, 2] = v.astype('uint8')\n",
    "    rgb = cv2.cvtColor(hsv.astype('uint8'), cv2.COLOR_HSV2RGB)\n",
    "    return(rgb, degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练数据中转向角为0的情况过多，将部分转向角为0的情况删除，设置丢弃率rate。\n",
    "def discard_zero_steering(degrees, rate):\n",
    "    steering_zero_idx = np.where(degrees == 0)\n",
    "    steering_zero_idx = steering_zero_idx[0]\n",
    "    size_del = int(len(steering_zero_idx) * rate)\n",
    "    return np.random.choice(steering_zero_idx, size = size_del, replace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: livelossplot in d:\\anaconda\\envs\\python36\\lib\\site-packages (0.5.3)\n",
      "Requirement already satisfied: bokeh in d:\\anaconda\\envs\\python36\\lib\\site-packages (from livelossplot) (2.2.3)\n",
      "Requirement already satisfied: ipython in d:\\anaconda\\envs\\python36\\lib\\site-packages (from livelossplot) (7.16.1)\n",
      "Requirement already satisfied: matplotlib in d:\\anaconda\\envs\\python36\\lib\\site-packages (from livelossplot) (3.3.3)\n",
      "Requirement already satisfied: pillow>=7.1.0 in d:\\anaconda\\envs\\python36\\lib\\site-packages (from bokeh->livelossplot) (8.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in d:\\anaconda\\envs\\python36\\lib\\site-packages (from bokeh->livelossplot) (3.7.4.3)\n",
      "Requirement already satisfied: tornado>=5.1 in d:\\anaconda\\envs\\python36\\lib\\site-packages (from bokeh->livelossplot) (6.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in d:\\anaconda\\envs\\python36\\lib\\site-packages (from bokeh->livelossplot) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.11.3 in d:\\anaconda\\envs\\python36\\lib\\site-packages (from bokeh->livelossplot) (1.19.5)\n",
      "Requirement already satisfied: packaging>=16.8 in d:\\anaconda\\envs\\python36\\lib\\site-packages (from bokeh->livelossplot) (20.8)\n",
      "Requirement already satisfied: PyYAML>=3.10 in d:\\anaconda\\envs\\python36\\lib\\site-packages (from bokeh->livelossplot) (5.3.1)\n",
      "Requirement already satisfied: Jinja2>=2.7 in d:\\anaconda\\envs\\python36\\lib\\site-packages (from bokeh->livelossplot) (2.11.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in d:\\anaconda\\envs\\python36\\lib\\site-packages (from Jinja2>=2.7->bokeh->livelossplot) (1.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in d:\\anaconda\\envs\\python36\\lib\\site-packages (from packaging>=16.8->bokeh->livelossplot) (2.4.7)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda\\envs\\python36\\lib\\site-packages (from python-dateutil>=2.1->bokeh->livelossplot) (1.15.0)\n",
      "Requirement already satisfied: jedi>=0.10 in d:\\anaconda\\envs\\python36\\lib\\site-packages (from ipython->livelossplot) (0.18.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in d:\\anaconda\\envs\\python36\\lib\\site-packages (from ipython->livelossplot) (3.0.8)\n",
      "Requirement already satisfied: pygments in d:\\anaconda\\envs\\python36\\lib\\site-packages (from ipython->livelossplot) (2.7.3)\n",
      "Requirement already satisfied: pickleshare in d:\\anaconda\\envs\\python36\\lib\\site-packages (from ipython->livelossplot) (0.7.5)\n",
      "Requirement already satisfied: backcall in d:\\anaconda\\envs\\python36\\lib\\site-packages (from ipython->livelossplot) (0.2.0)\n",
      "Requirement already satisfied: decorator in d:\\anaconda\\envs\\python36\\lib\\site-packages (from ipython->livelossplot) (4.4.2)\n",
      "Requirement already satisfied: traitlets>=4.2 in d:\\anaconda\\envs\\python36\\lib\\site-packages (from ipython->livelossplot) (4.3.3)\n",
      "Requirement already satisfied: setuptools>=18.5 in d:\\anaconda\\envs\\python36\\lib\\site-packages (from ipython->livelossplot) (51.0.0.post20201207)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\envs\\python36\\lib\\site-packages (from ipython->livelossplot) (0.4.4)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in d:\\anaconda\\envs\\python36\\lib\\site-packages (from jedi>=0.10->ipython->livelossplot) (0.8.1)\n",
      "Requirement already satisfied: wcwidth in d:\\anaconda\\envs\\python36\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->livelossplot) (0.2.5)\n",
      "Requirement already satisfied: ipython-genutils in d:\\anaconda\\envs\\python36\\lib\\site-packages (from traitlets>=4.2->ipython->livelossplot) (0.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\anaconda\\envs\\python36\\lib\\site-packages (from matplotlib->livelossplot) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\anaconda\\envs\\python36\\lib\\site-packages (from matplotlib->livelossplot) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "#为实时查看迭代过程中loss变化，安装livelossplot\n",
    "import sys \n",
    "sys.version\n",
    "! pip install livelossplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#网络训练（train.py）：\n",
    "import numpy as np\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, PReLU, BatchNormalization\n",
    "from keras.models import Sequential, Model\n",
    "from keras import backend as K\n",
    "from keras.regularizers import l2\n",
    "import os.path\n",
    "import csv\n",
    "import cv2\n",
    "import glob\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "from keras import callbacks\n",
    "import math\n",
    "from matplotlib import pyplot\n",
    "from livelossplot import PlotLossesKeras\n",
    "\n",
    "SEED = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def horizontal_flip(img, degree):\n",
    "    choice = np.random.choice([0, 1])\n",
    "    if choice == 1:\n",
    "        img, degree = cv2.flip(img, 1), -degree\n",
    "    return (img, degree)\n",
    "\n",
    "\n",
    "def random_brightness(img, degree):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    alpha = np.random.uniform(low=0.1, high=1.0, size=None)\n",
    "    v = hsv[:, :, 2]\n",
    "    v = v * alpha\n",
    "    hsv[:, :, 2] = v.astype('uint8')\n",
    "    rgb = cv2.cvtColor(hsv.astype('uint8'), cv2.COLOR_HSV2RGB)\n",
    "    return (rgb, degree)\n",
    "\n",
    "\n",
    "def left_right_random_swap(img_address, degree, degree_corr=1.0 / 4):\n",
    "    swap = np.random.choice(['L', 'R', 'C'])\n",
    "    if swap == 'L':\n",
    "        img_address = img_address.replace('center', 'left')\n",
    "        corrected_label = np.arctan(math.tan(degree) + degree_corr)\n",
    "        return (img_address, corrected_label)\n",
    "    elif swap == 'R':\n",
    "        img_address = img_address.replace('center', 'right')\n",
    "        corrected_label = np.arctan(math.tan(degree) - degree_corr)\n",
    "        return (img_address, corrected_label)\n",
    "    else:\n",
    "        return (img_address, degree)\n",
    "\n",
    "\n",
    "def discard_zero_steering(degrees, rate):\n",
    "    steering_zero_idx = np.where(degrees == 0)\n",
    "    steering_zero_idx = steering_zero_idx[0]\n",
    "    size_del = int(len(steering_zero_idx) * rate)\n",
    "    return np.random.choice(steering_zero_idx, size=size_del, replace=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(shape):\n",
    "    '''\n",
    "    预测方向盘角度: 以图像为输入, 预测方向盘的转动角度\n",
    "    shape: 输入图像的尺寸, 例如(128, 128, 3)\n",
    "    '''\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(8, (5, 5), strides=(1, 1), padding=\"valid\", input_shape=shape))\n",
    "    # model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(8, (5, 5), strides=(1, 1), padding=\"valid\", ))\n",
    "    # model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(16, (4, 4), strides=(1, 1), padding=\"valid\", ))\n",
    "    # model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(16, (5, 5), strides=(1, 1), padding=\"valid\", ))\n",
    "    # model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(128))\n",
    "    # model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Dense(50))\n",
    "    # model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Dense(10))\n",
    "    # model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "\n",
    "    adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
    "    model.compile(optimizer=adam, loss='mean_squared_error')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_transformation(img_address, degree, data_dir):\n",
    "    img_address, degree = left_right_random_swap(img_address, degree)\n",
    "    img = cv2.imread(img_address)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img, degree = random_brightness(img, degree)\n",
    "    img, degree = horizontal_flip(img, degree)\n",
    "    return (img, degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(x, y, batch_size, shape, training=True, data_dir='data/', monitor=True, yieldXY=True,\n",
    "                    discard_rate=0.95):\n",
    "    if training:\n",
    "        y_bag = []\n",
    "        x, y = shuffle(x, y)\n",
    "        new_x = x\n",
    "        new_y = y\n",
    "    else:\n",
    "        new_x = x\n",
    "        new_y = y\n",
    "\n",
    "    offset = 0\n",
    "    while True:\n",
    "        X = np.empty((batch_size, *shape))\n",
    "        Y = np.empty((batch_size, 1))\n",
    "\n",
    "        for example in range(batch_size):\n",
    "            img_address, img_steering = new_x[example + offset], new_y[example + offset]\n",
    "            # print(img_address)\n",
    "            if training:\n",
    "                img, img_steering = image_transformation(img_address, img_steering, data_dir)\n",
    "            else:\n",
    "                # img = cv2.imread(data_dir + img_address)\n",
    "                img = cv2.imread(img_address)\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            X[example, :, :, :] = cv2.resize(img[80:140, 0:320], (shape[0], shape[1])) / 255 - 0.5\n",
    "\n",
    "            Y[example] = img_steering\n",
    "            if training:\n",
    "                y_bag.append(img_steering)\n",
    "\n",
    "            if (example + 1) + offset > len(new_y) - 1:\n",
    "                x, y = shuffle(x, y)\n",
    "                rand_zero_idx = discard_zero_steering(y, rate=discard_rate)\n",
    "                new_x = x\n",
    "                new_y = y\n",
    "                new_x = np.delete(new_x, rand_zero_idx, axis=0)\n",
    "                new_y = np.delete(new_y, rand_zero_idx, axis=0)\n",
    "                offset = 0\n",
    "        if yieldXY:\n",
    "            yield (X, Y)\n",
    "        else:\n",
    "            yield X\n",
    "\n",
    "        offset = offset + batch_size\n",
    "        if training:\n",
    "            np.save('y_bag.npy', np.array(y_bag))\n",
    "            np.save('Xbatch_sample.npy', X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6389\n",
      "19167\n",
      "batch size: 8\n",
      "Train set size: 5111 | Validation set size: 1278\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    data_path = 'C:\\\\Users\\\\Zhangzhang\\\\Desktop'\n",
    "    with open('C:\\\\Users\\\\Zhangzhang\\\\Desktop\\\\driving_log.csv', 'r',encoding=\"utf-8\") as csvfile:\n",
    "        file_reader = csv.reader(csvfile, delimiter=',')\n",
    "        log = []\n",
    "        for row in file_reader:\n",
    "            log.append(row)\n",
    "\n",
    "    log = np.array(log)\n",
    "    print(len(log))\n",
    "    #print(len(ls_imgs))\n",
    "\n",
    "    # 判断图像文件数量是否等于csv日志文件中记录的数量\n",
    "    ls_imgs = glob.glob(r\"C:/Users/Zhangzhang/Desktop/IMG/*.jpg\")\n",
    "    print(len(ls_imgs))\n",
    "    #glob.glob(r\"C:/Users/Zhangzhang/Desktop/IMG/*.jpg\"))\n",
    "    assert len(ls_imgs) == len(log) * 3, 'number of images does not match'\n",
    "    # 使用20%的数据作为测试数据\n",
    "    validation_ratio = 0.2\n",
    "    shape = (128, 128, 3)\n",
    "    batch_size = 8\n",
    "    nb_epoch = 400\n",
    "\n",
    "    x_ = log[:, 0]\n",
    "    y_ = log[:, 3].astype(float)\n",
    "    x_, y_ = shuffle(x_, y_)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(x_, y_, test_size=validation_ratio, random_state=SEED)\n",
    "\n",
    "    print('batch size: {}'.format(batch_size))\n",
    "    print('Train set size: {} | Validation set size: {}'.format(len(X_train), len(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 124, 124, 8)       608       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 124, 124, 8)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 62, 62, 8)         0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 62, 62, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 58, 58, 8)         1608      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 58, 58, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 29, 29, 8)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 29, 29, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 16)        2064      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 26, 26, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 9, 9, 16)          6416      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 9, 9, 16)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 50,563\n",
      "Trainable params: 50,563\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.1) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-6uw63ony\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-2fea0ef3066e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m                               validation_data=batch_generator(X_val, y_val, batch_size, shape,\n\u001b[0;32m     20\u001b[0m                                                               training=False, monitor=False),\n\u001b[1;32m---> 21\u001b[1;33m                               epochs=nb_epoch, verbose=1, callbacks=callbacks_list)\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./trainHistoryDict.p'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile_pi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1859\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1860\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1861\u001b[1;33m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1862\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1863\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[1;32mD:\\anaconda\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1062\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1063\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1064\u001b[1;33m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[0;32m   1065\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1066\u001b[0m       \u001b[1;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[0;32m   1110\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1111\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1112\u001b[1;33m         model=model)\n\u001b[0m\u001b[0;32m   1113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1114\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[0;32m    777\u001b[0m     \u001b[1;31m# Since we have to know the dtype of the python generator when we build the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m     \u001b[1;31m# dataset, we have to look at a batch to infer the structure.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m     \u001b[0mpeek\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_peek_and_restore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m     \u001b[0mpeek\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_standardize_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m     \u001b[0mpeek\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_peek_and_restore\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    834\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_peek_and_restore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 836\u001b[1;33m     \u001b[0mpeek\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    837\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpeek\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitertools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpeek\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    838\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-adc915d47d3f>\u001b[0m in \u001b[0;36mbatch_generator\u001b[1;34m(x, y, batch_size, shape, training, data_dir, monitor, yieldXY, discard_rate)\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[1;31m# print(img_address)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m                 \u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_steering\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage_transformation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_address\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_steering\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m                 \u001b[1;31m# img = cv2.imread(data_dir + img_address)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-71ed9dc9793b>\u001b[0m in \u001b[0;36mimage_transformation\u001b[1;34m(img_address, degree, data_dir)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mimg_address\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdegree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mleft_right_random_swap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_address\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_address\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdegree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_brightness\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdegree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhorizontal_flip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.1) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-6uw63ony\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "    samples_per_epoch = batch_size\n",
    "    # 使得validation数据量大小为batch_size的整数陪\n",
    "    nb_val_samples = len(y_val) - len(y_val) % batch_size\n",
    "    model = get_model(shape)\n",
    "    print(model.summary())\n",
    "\n",
    "    # 根据validation loss保存最优模型\n",
    "    save_best = callbacks.ModelCheckpoint('best_model.h5', monitor='val_loss', verbose=1,\n",
    "                                          save_best_only=True, mode='min')\n",
    "\n",
    "    # 如果训练持续没有validation loss的提升, 提前结束训练，可通过更改patience参数确定终止条件。\n",
    "    early_stop = callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=400,\n",
    "                                         verbose=0, mode='auto')\n",
    "    callbacks_list = [early_stop, save_best, PlotLossesKeras()]\n",
    "\n",
    "    history = model.fit_generator(batch_generator(X_train, y_train, batch_size, shape, training=True),\n",
    "                                  steps_per_epoch=samples_per_epoch,\n",
    "                                  validation_steps=nb_val_samples // batch_size,\n",
    "                                  validation_data=batch_generator(X_val, y_val, batch_size, shape,\n",
    "                                                                  training=False, monitor=False),\n",
    "                                  epochs=nb_epoch, verbose=1, callbacks=callbacks_list)\n",
    "\n",
    "    with open('./trainHistoryDict.p', 'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)\n",
    "\n",
    "    pyplot.plot(history.history['loss'])\n",
    "    pyplot.plot(history.history['val_loss'])\n",
    "    pyplot.title('model train vs validation loss')\n",
    "    pyplot.ylabel('loss')\n",
    "    pyplot.xlabel('epoch')\n",
    "    pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "    pyplot.savefig('train_val_loss.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    " # 保存模型\n",
    "    with open('model.json', 'w') as f:\n",
    "        f.write(model.to_json())\n",
    "    model.save('model.h5')\n",
    "    print('Done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Downloading numpy-1.19.5-cp36-cp36m-win_amd64.whl (13.2 MB)\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-1.19.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
